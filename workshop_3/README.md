## AWS Workshop 3 - SageMaker Model Deployment and Application Development

### SageMaker Model Deployment: Bring-Your-Own-Container model deployment

[sagemaker_model_deployment](sagemaker_model_deployment): Jupyter Notebooks for deploying and testing the Bring-Your-Own-Container (SageMaker Decision Tree) model.

### Reference: Deploy a Hugging Face Pretrained Model to Amazon SageMaker Serverless Endpoint - Boto3 [Mia Chang]

Jupyter Notebook: https://github.com/aws/studio-lab-examples/blob/c154a9a009227c50e8af3be308fe475a7abd607f/connect-to-aws/Access_AWS_from_Studio_Lab_Deployment.ipynb

### SageMaker Text Generator

[sagemaker_text_generator](sagemaker_text_generator): Enter a prompt. Use a deployed SageMaker JumpStart Inference Endpoint for the Meta Llama 3.2 Instruct model to generate the remainder of the paragraph.

Please see [sagemaker_text_generator/README.md](sagemaker_text_generator/README.md) for deployment and text instructions.

### Bedrock Document Summarizer

[bedrock_document_summarizer](bedrock_document_summarizer): Upload a PDF document. Use a deployed SageMaker Inference Endpoint for the SageMaker JumpStart model (i.e., Open Llama 7B v2) and LangChain to generate a summarization of the uploaded document.

Please see [bedrock_document_summarizer/README.md](bedrock_document_summarizer/README.md) for deployment and text instructions.
